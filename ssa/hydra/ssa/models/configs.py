# Generated by configen, do not edit.
# See https://github.com/facebookresearch/hydra/tree/master/tools/configen
# fmt: off
# isort:skip_file
# flake8: noqa

from dataclasses import dataclass
from kit.torch.data import TrainingMode
from ssa.models.due.dkl import GPKernel
from ssa.models.due.fc_resnet import ActivationFn


@dataclass
class DUEConf:
    _target_: str = "ssa.models.DUE"
    num_features: int = 128
    depth: int = 4
    snorm_coeff: float = 0.95
    n_power_iterations: int = 1
    dropout_rate: float = 0.01
    activation_fn: ActivationFn = ActivationFn.relu
    num_inducing_points: int = 20
    num_inducing_point_refs: int = 1000
    kernel: GPKernel = GPKernel.matern12
    beta: float = 1.0
    weight_decay: float = 0.0
    lr: float = 0.0003
    lr_initial_restart: int = 10
    lr_restart_mult: int = 2
    lr_sched_interval: TrainingMode = TrainingMode.epoch
    lr_sched_freq: int = 1


@dataclass
class SimpleRegressionConf:
    _target_: str = "ssa.models.SimpleRegression"
    activation_fn: ActivationFn = ActivationFn.relu
    depth: int = 8
    dropout_rate: float = 0.95
    lr: float = 0.0003
    lr_initial_restart: int = 10
    lr_restart_mult: int = 2
    lr_sched_interval: TrainingMode = TrainingMode.epoch
    lr_sched_freq: int = 1
    n_power_iterations: int = 1
    num_features: int = 128
    snorm_coeff: float = 0.95
    weight_decay: float = 0.0
